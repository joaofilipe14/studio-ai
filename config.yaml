ollama:
  host: "http://localhost:11434"
  model: "llama3.1:8b"
  temperature: 0.1
  top_p: 0.9
  num_ctx: 8192

run:
  num_runs: 2
  max_steps: 12
  max_tool_calls_per_step: 6
  auto_snapshot: true
  max_replans: 2
  snapshot_keep: 20
  modes:
    - "PointToPoint"


paths:
  state: "memory/current_state.json"
  kb: "memory/knowledge_base.md"
  logs: "logs"
  backups: "backups"
  projects: "projects"